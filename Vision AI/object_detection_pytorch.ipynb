{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ranen\\OneDrive\\Documents\\GitHub\\Projects\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ranen\\OneDrive\\Documents\\GitHub\\Projects\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "FasterRCNN(\n  (transform): GeneralizedRCNNTransform(\n      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n  )\n  (backbone): BackboneWithFPN(\n    (body): IntermediateLayerGetter(\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n      (relu): ReLU(inplace=True)\n      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (layer1): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): FrozenBatchNorm2d(256, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer2): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(512, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer3): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(1024, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (4): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (5): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer4): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(2048, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n    )\n    (fpn): FeaturePyramidNetwork(\n      (inner_blocks): ModuleList(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (layer_blocks): ModuleList(\n        (0-3): 4 x Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (extra_blocks): LastLevelMaxPool()\n    )\n  )\n  (rpn): RegionProposalNetwork(\n    (anchor_generator): AnchorGenerator()\n    (head): RPNHead(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n      )\n      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (roi_heads): RoIHeads(\n    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n    (box_head): TwoMLPHead(\n      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n    )\n    (box_predictor): FastRCNNPredictor(\n      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n    )\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ig = Image.open(\"kitchen.jpg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "transform = T.ToTensor()\n",
    "img = transform(ig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model([img])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'boxes': tensor([[2378.7104, 1201.6443, 3759.0864, 3005.5183],\n          [2514.9724,  282.1148, 3715.1023,  943.0298],\n          [1953.4280, 1305.9213, 2184.1733, 1520.9231],\n          [  15.8513,   76.0517, 1114.8868, 2950.6819],\n          [3629.8442, 1382.5638, 3847.2937, 1639.4873],\n          [3653.1221, 1197.7579, 3737.7043, 1390.1691],\n          [1305.2100, 1256.2178, 1557.9755, 1465.0967],\n          [1917.2402, 1353.1849, 1978.4221, 1503.0969],\n          [3732.3918, 1399.3971, 3850.0002, 1635.5522],\n          [3704.6548, 1193.6284, 3826.8447, 1391.9979],\n          [1637.1537, 1405.1533, 1949.2164, 1519.4946],\n          [3616.4927, 1217.0496, 3651.5327, 1393.4541],\n          [2319.2947, 1183.6920, 2430.1470, 1540.3967],\n          [3598.1560, 1208.9083, 3642.0820, 1389.3816],\n          [3900.2686, 1482.7366, 4026.3923, 1670.4412],\n          [3730.8540, 1176.0966, 3793.3303, 1272.3936],\n          [3019.2156, 1289.8981, 3081.5891, 1319.1218],\n          [2423.0327, 1369.0264, 3309.3386, 2647.3745],\n          [1087.5760, 1421.2699, 1323.7504, 1576.7335],\n          [3817.1428, 1140.3972, 3982.9912, 1282.7039],\n          [1654.3771, 1264.5184, 1863.1371, 1449.5668],\n          [3562.7656, 1199.3615, 3631.1885, 1384.9568],\n          [1109.8779, 1802.9025, 1470.2312, 2923.9773],\n          [3642.5310, 1199.3669, 3694.8459, 1386.1578],\n          [3147.4966, 1826.0431, 3690.8374, 2651.1819],\n          [3906.8145, 1467.9231, 4027.4612, 1667.5059],\n          [1860.5149, 1424.2391, 1926.8082, 1511.0889],\n          [1684.0046, 1321.7814, 1797.0516, 1426.2048],\n          [3775.9387, 1210.9573, 3842.9399, 1288.2627],\n          [3885.7695, 1505.9049, 3975.6753, 1645.3563],\n          [3631.8909, 1212.2476, 3672.7412, 1386.9943],\n          [3758.2424, 1306.3534, 3843.4910, 1387.4222],\n          [3630.2314, 1146.3655, 3715.6685, 1352.4359],\n          [1829.0675, 1456.8782, 1884.6219, 1519.4420],\n          [1644.2911, 1415.0150, 1824.1490, 1504.6748],\n          [2498.7192, 1626.6677, 3022.0398, 2504.8584],\n          [3310.5945, 1916.3292, 3561.1111, 2527.6694],\n          [1078.7977, 1436.5021, 1226.7482, 1568.8115],\n          [3818.3313, 1136.5439, 3987.8457, 1293.1050],\n          [3675.9380, 1177.2727, 3771.0259, 1362.4501],\n          [3703.7305, 1192.4730, 3827.8923, 1379.0295],\n          [1633.5331, 1326.4659, 1889.0986, 1510.9050],\n          [3649.4539, 1193.3442, 3739.9194, 1382.4868],\n          [1742.7190, 1421.0170, 1919.0752, 1509.6862],\n          [3312.6064, 1916.8502, 3557.7158, 2529.5518],\n          [1700.8994, 1308.5751, 1857.7145, 1430.0444],\n          [1769.1742, 1262.2775, 1858.4850, 1413.5035],\n          [2179.3650, 1353.3285, 2311.0278, 1532.0820],\n          [3726.5425, 1248.9001, 3856.4485, 1382.3071],\n          [3837.6458, 1268.6593, 4006.9409, 1492.3506],\n          [2522.4387, 1856.2726, 2691.6487, 2407.8364],\n          [3546.2949, 1198.5066, 3621.4038, 1367.0117],\n          [1850.2867, 1344.5243, 1971.9471, 1510.3750],\n          [3816.3672, 1141.7717, 3991.2593, 1292.9340],\n          [3630.6755, 1680.8894, 4032.0000, 2980.2207],\n          [3544.5359, 1198.7430, 3607.7766, 1362.1438],\n          [3577.2400, 1197.3735, 3694.5376, 1389.3044],\n          [3880.1152, 1349.0029, 4023.0371, 1674.2405],\n          [3893.5012, 1502.6890, 4032.0000, 1663.5081],\n          [ 780.9230,  142.6433, 1088.0225, 2367.1443],\n          [1844.2468, 1346.8358, 1924.4974, 1423.2574],\n          [3586.0547, 1592.6838, 4018.7002, 1769.3347],\n          [1883.4708, 1364.1984, 1947.0044, 1505.0691],\n          [1763.3512, 1424.9137, 1889.3933, 1519.0378],\n          [2936.7209, 1550.5470, 3714.1699, 2810.9348],\n          [1933.7456, 1319.2244, 2206.1658, 1530.1495],\n          [1660.6548, 1334.8042, 1809.4221, 1466.1815],\n          [3876.2637, 1503.0492, 4031.4607, 1678.8411],\n          [1787.2362, 1259.7579, 1861.6666, 1429.9569],\n          [3901.6289, 1440.8240, 4019.8730, 1668.9375],\n          [1857.3948, 1406.0957, 1935.2451, 1505.7258],\n          [3612.8176, 1204.6106, 3648.5957, 1393.4318],\n          [3775.6453, 1210.4208, 3843.4546, 1288.4868],\n          [3598.6677, 1378.8647, 3846.4814, 1591.8960],\n          [3623.0942, 1294.9836, 4032.0000, 1824.7627],\n          [3731.1250, 1176.0461, 3793.5474, 1272.4412]]),\n  'labels': tensor([79, 78, 80, 82, 47, 50, 51, 44, 47, 50, 51, 50, 44, 50, 47, 50, 85, 79,\n          62, 62, 52, 50, 79, 50, 79, 86, 53, 52, 50, 47, 50, 50, 50, 53, 51, 79,\n          78, 62, 77, 50, 49, 51, 49, 51, 79, 52, 52, 47, 50, 46, 79, 49, 44, 49,\n          79, 50, 50, 46, 51, 82, 51, 81, 44, 53, 79, 78, 52, 81, 44, 44, 51, 49,\n          49, 51, 67, 49]),\n  'scores': tensor([0.9969, 0.9950, 0.9499, 0.9315, 0.8483, 0.8004, 0.7571, 0.7472, 0.7410,\n          0.6416, 0.6091, 0.5329, 0.5316, 0.5193, 0.4864, 0.4818, 0.4708, 0.4660,\n          0.4601, 0.4149, 0.3937, 0.3474, 0.3003, 0.2527, 0.2352, 0.2251, 0.2156,\n          0.2095, 0.2031, 0.2028, 0.1938, 0.1753, 0.1691, 0.1639, 0.1619, 0.1563,\n          0.1554, 0.1475, 0.1311, 0.1296, 0.1276, 0.1241, 0.1226, 0.1171, 0.1129,\n          0.1115, 0.1078, 0.1059, 0.1030, 0.0954, 0.0909, 0.0888, 0.0872, 0.0859,\n          0.0848, 0.0848, 0.0835, 0.0824, 0.0802, 0.0752, 0.0689, 0.0684, 0.0670,\n          0.0664, 0.0653, 0.0614, 0.0604, 0.0602, 0.0593, 0.0593, 0.0569, 0.0559,\n          0.0557, 0.0552, 0.0529, 0.0512])}]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "bboxes, labels, scores = pred[0][\"boxes\"], pred[0][\"labels\"], pred[0][\"scores\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "num = torch.argwhere(scores > 0.75).shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "coco_names = [\"person\" , \"bicycle\" , \"car\" , \"motorcycle\" , \"airplane\" , \"bus\" , \"train\" , \"truck\" , \"boat\" , \"traffic light\" , \"fire hydrant\" , \"street sign\" , \"stop sign\" , \"parking meter\" , \"bench\" , \"bird\" , \"cat\" , \"dog\" , \"horse\" , \"sheep\" , \"cow\" , \"elephant\" , \"bear\" , \"zebra\" , \"giraffe\" , \"hat\" , \"backpack\" , \"umbrella\" , \"shoe\" , \"eye glasses\" , \"handbag\" , \"tie\" , \"suitcase\" ,\n",
    "\"frisbee\" , \"skis\" , \"snowboard\" , \"sports ball\" , \"kite\" , \"baseball bat\" ,\n",
    "\"baseball glove\" , \"skateboard\" , \"surfboard\" , \"tennis racket\" , \"bottle\" ,\n",
    "\"plate\" , \"wine glass\" , \"cup\" , \"fork\" , \"knife\" , \"spoon\" , \"bowl\" ,\n",
    "\"banana\" , \"apple\" , \"sandwich\" , \"orange\" , \"broccoli\" , \"carrot\" , \"hot dog\" ,\n",
    "\"pizza\" , \"donut\" , \"cake\" , \"chair\" , \"couch\" , \"potted plant\" , \"bed\" ,\n",
    "\"mirror\" , \"dining table\" , \"window\" , \"desk\" , \"toilet\" , \"door\" , \"tv\" ,\n",
    "\"laptop\" , \"mouse\" , \"remote\" , \"keyboard\" , \"cell phone\" , \"microwave\" ,\n",
    "\"oven\" , \"toaster\" , \"sink\" , \"refrigerator\" , \"blender\" , \"book\" ,\n",
    "\"clock\" , \"vase\" , \"scissors\" , \"teddy bear\" , \"hair drier\" , \"toothbrush\" , \"hair brush\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "igg = cv2.imread(\"kitchen.jpg\")\n",
    "for i in range(num):\n",
    "    x1, y1, x2, y2 = bboxes[i].numpy().astype(\"int\")\n",
    "    class_name = coco_names[labels.numpy()[i] - 1]\n",
    "    igg = cv2.rectangle(igg, (x1, y1) , (x2, y2) , (0, 255, 0), 1)\n",
    "    igg = cv2.putText(igg, class_name, (x1, y1 - 10) , font, 3, (0, 0, 255), 4, cv2.LINE_AA)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2378.7104, 1201.6443, 3759.0864, 3005.5183],\n        [2514.9724,  282.1148, 3715.1023,  943.0298],\n        [1953.4280, 1305.9213, 2184.1733, 1520.9231],\n        [  15.8513,   76.0517, 1114.8868, 2950.6819],\n        [3629.8442, 1382.5638, 3847.2937, 1639.4873],\n        [3653.1221, 1197.7579, 3737.7043, 1390.1691],\n        [1305.2100, 1256.2178, 1557.9755, 1465.0967],\n        [1917.2402, 1353.1849, 1978.4221, 1503.0969],\n        [3732.3918, 1399.3971, 3850.0002, 1635.5522],\n        [3704.6548, 1193.6284, 3826.8447, 1391.9979],\n        [1637.1537, 1405.1533, 1949.2164, 1519.4946],\n        [3616.4927, 1217.0496, 3651.5327, 1393.4541],\n        [2319.2947, 1183.6920, 2430.1470, 1540.3967],\n        [3598.1560, 1208.9083, 3642.0820, 1389.3816],\n        [3900.2686, 1482.7366, 4026.3923, 1670.4412],\n        [3730.8540, 1176.0966, 3793.3303, 1272.3936],\n        [3019.2156, 1289.8981, 3081.5891, 1319.1218],\n        [2423.0327, 1369.0264, 3309.3386, 2647.3745],\n        [1087.5760, 1421.2699, 1323.7504, 1576.7335],\n        [3817.1428, 1140.3972, 3982.9912, 1282.7039],\n        [1654.3771, 1264.5184, 1863.1371, 1449.5668],\n        [3562.7656, 1199.3615, 3631.1885, 1384.9568],\n        [1109.8779, 1802.9025, 1470.2312, 2923.9773],\n        [3642.5310, 1199.3669, 3694.8459, 1386.1578],\n        [3147.4966, 1826.0431, 3690.8374, 2651.1819],\n        [3906.8145, 1467.9231, 4027.4612, 1667.5059],\n        [1860.5149, 1424.2391, 1926.8082, 1511.0889],\n        [1684.0046, 1321.7814, 1797.0516, 1426.2048],\n        [3775.9387, 1210.9573, 3842.9399, 1288.2627],\n        [3885.7695, 1505.9049, 3975.6753, 1645.3563],\n        [3631.8909, 1212.2476, 3672.7412, 1386.9943],\n        [3758.2424, 1306.3534, 3843.4910, 1387.4222],\n        [3630.2314, 1146.3655, 3715.6685, 1352.4359],\n        [1829.0675, 1456.8782, 1884.6219, 1519.4420],\n        [1644.2911, 1415.0150, 1824.1490, 1504.6748],\n        [2498.7192, 1626.6677, 3022.0398, 2504.8584],\n        [3310.5945, 1916.3292, 3561.1111, 2527.6694],\n        [1078.7977, 1436.5021, 1226.7482, 1568.8115],\n        [3818.3313, 1136.5439, 3987.8457, 1293.1050],\n        [3675.9380, 1177.2727, 3771.0259, 1362.4501],\n        [3703.7305, 1192.4730, 3827.8923, 1379.0295],\n        [1633.5331, 1326.4659, 1889.0986, 1510.9050],\n        [3649.4539, 1193.3442, 3739.9194, 1382.4868],\n        [1742.7190, 1421.0170, 1919.0752, 1509.6862],\n        [3312.6064, 1916.8502, 3557.7158, 2529.5518],\n        [1700.8994, 1308.5751, 1857.7145, 1430.0444],\n        [1769.1742, 1262.2775, 1858.4850, 1413.5035],\n        [2179.3650, 1353.3285, 2311.0278, 1532.0820],\n        [3726.5425, 1248.9001, 3856.4485, 1382.3071],\n        [3837.6458, 1268.6593, 4006.9409, 1492.3506],\n        [2522.4387, 1856.2726, 2691.6487, 2407.8364],\n        [3546.2949, 1198.5066, 3621.4038, 1367.0117],\n        [1850.2867, 1344.5243, 1971.9471, 1510.3750],\n        [3816.3672, 1141.7717, 3991.2593, 1292.9340],\n        [3630.6755, 1680.8894, 4032.0000, 2980.2207],\n        [3544.5359, 1198.7430, 3607.7766, 1362.1438],\n        [3577.2400, 1197.3735, 3694.5376, 1389.3044],\n        [3880.1152, 1349.0029, 4023.0371, 1674.2405],\n        [3893.5012, 1502.6890, 4032.0000, 1663.5081],\n        [ 780.9230,  142.6433, 1088.0225, 2367.1443],\n        [1844.2468, 1346.8358, 1924.4974, 1423.2574],\n        [3586.0547, 1592.6838, 4018.7002, 1769.3347],\n        [1883.4708, 1364.1984, 1947.0044, 1505.0691],\n        [1763.3512, 1424.9137, 1889.3933, 1519.0378],\n        [2936.7209, 1550.5470, 3714.1699, 2810.9348],\n        [1933.7456, 1319.2244, 2206.1658, 1530.1495],\n        [1660.6548, 1334.8042, 1809.4221, 1466.1815],\n        [3876.2637, 1503.0492, 4031.4607, 1678.8411],\n        [1787.2362, 1259.7579, 1861.6666, 1429.9569],\n        [3901.6289, 1440.8240, 4019.8730, 1668.9375],\n        [1857.3948, 1406.0957, 1935.2451, 1505.7258],\n        [3612.8176, 1204.6106, 3648.5957, 1393.4318],\n        [3775.6453, 1210.4208, 3843.4546, 1288.4868],\n        [3598.6677, 1378.8647, 3846.4814, 1591.8960],\n        [3623.0942, 1294.9836, 4032.0000, 1824.7627],\n        [3731.1250, 1176.0461, 3793.5474, 1272.4412]])"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# Resize the image to a smaller size\n",
    "img_resized = cv2.resize(igg, (1800, 1000))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "cv2.imshow('Image', img_resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
